{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0ed6cc23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import boto3\n",
    "import pandas as pd\n",
    "from io import StringIO\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import numpy as np\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a69ebbd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index                         0\n",
      "aqi_index                     0\n",
      "co                            0\n",
      "no                            0\n",
      "no2                           0\n",
      "o3                            0\n",
      "so2                           0\n",
      "pm2_5                         0\n",
      "pm10                          0\n",
      "nh3                           0\n",
      "temperature_2m                0\n",
      "relative_humidity_2m          0\n",
      "precipitation                 0\n",
      "wind_speed_10m                0\n",
      "wind_direction_10m            0\n",
      "surface_pressure              0\n",
      "dew_point_2m                  0\n",
      "apparent_temperature          0\n",
      "shortwave_radiation           0\n",
      "et0_fao_evapotranspiration    0\n",
      "year                          0\n",
      "month                         0\n",
      "day                           0\n",
      "hour                          0\n",
      "Calculated_AQI                0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Your AWS credentials and bucket info\n",
    "bucket_name = 'my-feature-store-data'\n",
    "s3_key = 'pipeline-data/data.csv'  # Example: \"pipeline-data/data.csv\"\n",
    "\n",
    "# Create an S3 client\n",
    "s3 = boto3.client(\n",
    "    's3',\n",
    "    aws_access_key_id= os.getenv('AWS_ACCESS_KEY_ID'),\n",
    "    aws_secret_access_key=os.getenv('AWS_SECRET_ACCESS_KEY'),\n",
    ")\n",
    "\n",
    "# Fetch the object from S3\n",
    "response = s3.get_object(Bucket=bucket_name, Key=s3_key)\n",
    "\n",
    "# Read the CSV content\n",
    "csv_data = response['Body'].read().decode('utf-8')\n",
    "\n",
    "# Convert to DataFrame\n",
    "df = pd.read_csv(StringIO(csv_data))\n",
    "\n",
    "# Done!\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0cce67d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "# Step 4: Define target and features\n",
    "# Step 4: Define targets and features\n",
    "target_columns = [\"aqi_index\", \"Calculated_AQI\"]\n",
    "targets = df[target_columns]\n",
    "X = df.drop(columns=target_columns)\n",
    "\n",
    "# Step 5: Final check for datetime columns\n",
    "X = X.select_dtypes(exclude=[\"datetime64[ns]\"])\n",
    "\n",
    "# Step 6: Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, targets, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "414706e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.linear_model import LinearRegression, Ridge\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import joblib\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c81e2291",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Random_Forest...\n",
      "  Target: aqi_index\n",
      "    RMSE: 0.323664506854938\n",
      "    MAE: 0.1996290739600245\n",
      "    R²: 0.8755245480051466\n",
      "  Target: Calculated_AQI\n",
      "    RMSE: 7.300486707695632\n",
      "    MAE: 1.6121383883111136\n",
      "    R²: 0.9949740847488451\n",
      "  Average RMSE: 3.8120756072752853\n",
      "\n",
      "Training Gradient_Boosting...\n",
      "  Target: aqi_index\n",
      "    RMSE: 0.049020969329610885\n",
      "    MAE: 0.016204030706548928\n",
      "    R²: 0.997144663171603\n",
      "  Target: Calculated_AQI\n",
      "    RMSE: 6.013866334993563\n",
      "    MAE: 3.117307613737743\n",
      "    R²: 0.9965894919863428\n",
      "  Average RMSE: 3.031443652161587\n",
      "\n",
      "Training Linear_Regression...\n",
      "  Target: aqi_index\n",
      "    RMSE: 0.5855752618949703\n",
      "    MAE: 0.4690884869791563\n",
      "    R²: 0.5925643745372393\n",
      "  Target: Calculated_AQI\n",
      "    RMSE: 84.23190155931523\n",
      "    MAE: 62.0356708762222\n",
      "    R²: 0.3309404991271254\n",
      "  Average RMSE: 42.4087384106051\n",
      "\n",
      "Training Ridge_Regression...\n",
      "  Target: aqi_index\n",
      "    RMSE: 0.5883819817701395\n",
      "    MAE: 0.47297138652351756\n",
      "    R²: 0.5886492560728201\n",
      "  Target: Calculated_AQI\n",
      "    RMSE: 84.53955294188049\n",
      "    MAE: 62.40684527375095\n",
      "    R²: 0.32604418360476195\n",
      "  Average RMSE: 42.563967461825314\n",
      "\n",
      "Training SVR...\n",
      "  Target: aqi_index\n",
      "    RMSE: 0.4238961722589369\n",
      "    MAE: 0.2929934160222826\n",
      "    R²: 0.7864927889677297\n",
      "  Target: Calculated_AQI\n",
      "    RMSE: 93.77550614954143\n",
      "    MAE: 52.74085229245246\n",
      "    R²: 0.1707406712888253\n",
      "  Average RMSE: 47.09970116090018\n",
      "\n",
      "Training Neural_Network...\n",
      "  Target: aqi_index\n",
      "    RMSE: 2.3783054197331412\n",
      "    MAE: 1.7940923517757115\n",
      "    R²: -5.720921281181228\n",
      "  Target: Calculated_AQI\n",
      "    RMSE: 33.13316642377875\n",
      "    MAE: 18.033989597332866\n",
      "    R²: 0.8964768648863168\n",
      "  Average RMSE: 17.755735921755946\n",
      "\n",
      "\n",
      "Best model: Gradient_Boosting (Average RMSE = 3.03)\n",
      "\n",
      "Summary of Model Performance:\n",
      "               Model  RMSE_aqi_index  MAE_aqi_index  R²_aqi_index  \\\n",
      "0      Random_Forest        0.323665       0.199629      0.875525   \n",
      "1  Gradient_Boosting        0.049021       0.016204      0.997145   \n",
      "2  Linear_Regression        0.585575       0.469088      0.592564   \n",
      "3   Ridge_Regression        0.588382       0.472971      0.588649   \n",
      "4                SVR        0.423896       0.292993      0.786493   \n",
      "5     Neural_Network        2.378305       1.794092     -5.720921   \n",
      "\n",
      "   RMSE_Calculated_AQI  MAE_Calculated_AQI  R²_Calculated_AQI   Avg_RMSE  \n",
      "0             7.300487            1.612138           0.994974   3.812076  \n",
      "1             6.013866            3.117308           0.996589   3.031444  \n",
      "2            84.231902           62.035671           0.330940  42.408738  \n",
      "3            84.539553           62.406845           0.326044  42.563967  \n",
      "4            93.775506           52.740852           0.170741  47.099701  \n",
      "5            33.133166           18.033990           0.896477  17.755736  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Import additional required libraries\n",
    "from io import BytesIO\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "\n",
    "# ✅ Step 3: Define Models with MultiOutput capability\n",
    "models = {\n",
    "    \"Random_Forest\": RandomForestRegressor(n_estimators=300, max_depth=10, random_state=42),\n",
    "    \"Gradient_Boosting\": MultiOutputRegressor(GradientBoostingRegressor(n_estimators=300, max_depth=3, random_state=42)),\n",
    "    \"Linear_Regression\": LinearRegression(),\n",
    "    \"Ridge_Regression\": Ridge(alpha=1.0),\n",
    "    \"SVR\": MultiOutputRegressor(SVR()),\n",
    "    \"Neural_Network\": MultiOutputRegressor(MLPRegressor(max_iter=200, random_state=42))\n",
    "}\n",
    "\n",
    "# -----------------------\n",
    "# ✅ Step 4: Train and Evaluate\n",
    "results = []\n",
    "best_model = None\n",
    "best_model_name = None\n",
    "best_avg_rmse = float(\"inf\")\n",
    "\n",
    "for model_name, model in models.items():\n",
    "    print(f\"Training {model_name}...\")\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Calculate metrics for each target\n",
    "    model_results = {\"Model\": model_name}\n",
    "    rmse_scores = []\n",
    "    \n",
    "    for i, col in enumerate(target_columns):\n",
    "        rmse = np.sqrt(mean_squared_error(y_test.iloc[:, i], y_pred[:, i]))\n",
    "        mae = mean_absolute_error(y_test.iloc[:, i], y_pred[:, i])\n",
    "        r2 = r2_score(y_test.iloc[:, i], y_pred[:, i])\n",
    "        \n",
    "        rmse_scores.append(rmse)\n",
    "        model_results[f\"RMSE_{col}\"] = rmse\n",
    "        model_results[f\"MAE_{col}\"] = mae\n",
    "        model_results[f\"R²_{col}\"] = r2\n",
    "        \n",
    "        print(f\"  Target: {col}\")\n",
    "        print(f\"    RMSE: {rmse}\")\n",
    "        print(f\"    MAE: {mae}\")\n",
    "        print(f\"    R²: {r2}\")\n",
    "    \n",
    "    # Calculate average RMSE across all targets\n",
    "    avg_rmse = np.mean(rmse_scores)\n",
    "    model_results[\"Avg_RMSE\"] = avg_rmse\n",
    "    results.append(model_results)\n",
    "    \n",
    "    print(f\"  Average RMSE: {avg_rmse}\\n\")\n",
    "    \n",
    "    if avg_rmse < best_avg_rmse:\n",
    "        best_avg_rmse = avg_rmse\n",
    "        best_model = model\n",
    "        best_model_name = model_name\n",
    "\n",
    "# -----------------------\n",
    "# Step 5: Save Best Model Locally\n",
    "print(f\"\\nBest model: {best_model_name} (Average RMSE = {best_avg_rmse:.2f})\")\n",
    "# joblib.dump(best_model, \"best_model.pkl\")\n",
    "\n",
    "\n",
    "# -----------------------\n",
    "# Step 7: Summary\n",
    "results_df = pd.DataFrame(results)\n",
    "print(\"\\nSummary of Model Performance:\")\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "59c321a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import json\n",
    "import sklearn\n",
    "import numpy as np\n",
    "from io import BytesIO\n",
    "\n",
    "S3_MODEL_KEY = \"models/best_model.pkl\"\n",
    "S3_METADATA_KEY = \"models/best_model_metadata.json\"\n",
    "\n",
    "def upload_model_to_s3(model, bucket_name, s3_client):\n",
    "    # --- Save model to BytesIO buffer ---\n",
    "    model_buffer = BytesIO()\n",
    "    joblib.dump(model, model_buffer)\n",
    "    model_buffer.seek(0)\n",
    "    s3_client.upload_fileobj(model_buffer, Bucket=bucket_name, Key=S3_MODEL_KEY)\n",
    "    print(f\"✅ Model uploaded to s3://{bucket_name}/{S3_MODEL_KEY}\")\n",
    "\n",
    "    # --- Save version metadata ---\n",
    "    metadata = {\n",
    "        \"sklearn_version\": sklearn.__version__,\n",
    "        \"numpy_version\": np.__version__,\n",
    "        \"model_type\": type(model).__name__,\n",
    "    }\n",
    "\n",
    "    metadata_buffer = BytesIO()\n",
    "    metadata_buffer.write(json.dumps(metadata).encode(\"utf-8\"))\n",
    "    metadata_buffer.seek(0)\n",
    "    s3_client.upload_fileobj(metadata_buffer, Bucket=bucket_name, Key=S3_METADATA_KEY)\n",
    "    print(f\"✅ Metadata uploaded to s3://{bucket_name}/{S3_METADATA_KEY}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1580b5fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Model uploaded to s3://my-feature-store-data/models/best_model.pkl\n",
      "✅ Metadata uploaded to s3://my-feature-store-data/models/best_model_metadata.json\n"
     ]
    }
   ],
   "source": [
    "upload_model_to_s3(best_model, bucket_name, s3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c13943f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
