name: Hourly Data Pipeline

on:
  schedule:
    - cron: '0 * * * *'  # Run every hour
  workflow_dispatch:  # Allow manual triggering

jobs:
  run-data-pipeline:
    runs-on: ubuntu-latest
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v3
        
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.10'
          
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install jupyter nbconvert pandas numpy boto3 requests matplotlib seaborn scikit-learn shap python-dotenv 
          
      - name: Run feature extraction from API
        run: |
          jupyter nbconvert --to script feature_extract_from_api_hourly.ipynb
          python feature_extract_from_api_hourly.py
          
      - name: Run data extraction
        run: |
          jupyter nbconvert --to script extract_data.ipynb
          python extract_data.py
          
      - name: Run EDA and cleaning
        run: |
          jupyter nbconvert --to script EDA.ipynb
          python EDA.py
          
      - name: Upload to AWS
        run: |
          jupyter nbconvert --to script feature_upload_aws.ipynb
          python feature_upload_aws.py
        env:
          AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}